Training Loss,Test Loss
0.849704817199707,0.3720643646240234
0.7353543462117513,0.22689686126708986
0.7119749537150065,0.21662450103759764
0.6992548683166504,0.21168137969970702
0.6916611152648926,0.20931498565673828
0.6863287445068359,0.20734804992675782
0.6821969380696614,0.20640194854736327
0.6787587117513021,0.20587906799316405
0.675871186319987,0.20474417266845704
0.6734386171976725,0.20379859161376954
0.671210907236735,0.20366675262451173
0.6692667790730794,0.2025160598754883
0.6675704645792643,0.20249881744384765
0.6661334790547688,0.2017880844116211
0.6646622009277344,0.20088572387695314
0.6634621439615885,0.20086407623291017
0.6621921750386556,0.2011478012084961
0.6608977834065756,0.20123819885253907
0.6597975133260091,0.20009756164550782
0.6588508829752604,0.1999028564453125
0.6575736920674642,0.20005934600830078
0.6567330121358236,0.19927046661376954
0.6558430386861165,0.1995232650756836
0.6550152961730957,0.1988667037963867
0.6541380544026693,0.19891187744140626
0.6534821016947429,0.19824730377197267
0.6528547823588053,0.1988903579711914
0.6524357513427734,0.19900294647216796
0.6514833615620931,0.1980929656982422
0.6505935981750488,0.19830633392333985
0.6503890157063802,0.19845604248046875
0.6494873390197754,0.19825092010498047
0.645286531829834,0.19826060485839844
0.6448417162577311,0.19677489471435547
0.6446105992635092,0.1968191680908203
0.6444825019836425,0.19671495513916015
0.6444810600280761,0.19676589965820312
0.6441916386922201,0.19662174682617187
0.6441288297017416,0.19665741271972656
0.6440627670288086,0.19662861022949218
0.643926124827067,0.19661487731933594
0.6435446286519368,0.1965701629638672
0.6436390195210775,0.19659903411865234
0.6435650283813477,0.19664357299804688
0.6435135938008626,0.19653690948486327
0.6435033432006836,0.19653350830078126
0.6434856046040853,0.19661317443847656
0.6435374626159668,0.19652252044677734
0.6433592458089192,0.19653528442382812
0.6434291931152344,0.1965978713989258
