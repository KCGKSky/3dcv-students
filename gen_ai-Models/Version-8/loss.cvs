Training Loss,Test Loss
0.944034267171224,0.5849978637695312
0.8500128626505534,0.34831353759765626
0.8285652414957683,0.3368353240966797
0.8159328684488932,0.33157012634277344
0.8073908208211263,0.3263787872314453
0.8005933171590169,0.3238356628417969
0.7947455134073893,0.32260901794433594
0.7891240417480468,0.31977843322753907
0.7855146341959636,0.3168535217285156
0.7814706975301107,0.3156089538574219
0.7788917836507161,0.31489134521484374
0.7758298563639323,0.3157477783203125
0.7734608591715495,0.3126158935546875
0.7716114334106445,0.3150929077148438
0.7691275919596354,0.31111249694824217
0.7673081583658854,0.3110511962890625
0.7657399815877278,0.30984319763183593
0.76423284962972,0.31323906860351564
0.7625423263549804,0.30940741271972655
0.7614050267537434,0.31062369689941405
0.7601016545613607,0.3088587677001953
0.7582177586873372,0.3074749206542969
0.7575610356648763,0.3085533508300781
0.7563690180460612,0.3082092041015625
0.7546407831827799,0.3081154510498047
0.74818330078125,0.3076502838134766
0.7474095779418946,0.30525477600097656
0.7470747080485026,0.30505906066894534
0.7467719172159831,0.30510340270996095
0.7465513559977214,0.3050374084472656
0.746209012858073,0.30479459533691405
0.7460132217407227,0.30488431701660157
0.745787794494629,0.30488294677734373
0.7456549748738607,0.3047345977783203
0.7452643295288086,0.30473079833984373
0.7451158284505208,0.30472978820800783
0.7450084849039713,0.30475638427734375
0.7444452565511067,0.30464923706054686
0.7445349604288737,0.3045518005371094
0.7443873057047526,0.30461293334960937
0.7442580434163412,0.30459358215332033
0.7443689463297526,0.30456372375488283
0.7442904525756836,0.30458004455566406
0.7442244817097982,0.3046434844970703
0.7442043360392253,0.3045447509765625
0.7442182779947917,0.3045947235107422
0.744317295328776,0.3045072174072266
0.744257090250651,0.304572900390625
0.7442651392618815,0.30462413330078125
0.7441761525472005,0.3046031005859375
