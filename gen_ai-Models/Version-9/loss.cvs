Training Loss,Test Loss
0.9587951527913412,0.5827583435058594
0.8682267425537109,0.3586337127685547
0.8470632197062175,0.3456421020507813
0.8348218002319336,0.3393012115478516
0.8265322896321614,0.3325965850830078
0.8204224527994791,0.333759912109375
0.8145831212361654,0.3300605285644531
0.8110240910847982,0.32797281188964844
0.8069687494913736,0.3260400970458984
0.8038180979410807,0.3265150085449219
0.8005171747843425,0.3226929748535156
0.798349062093099,0.3212521026611328
0.7957901524861654,0.3211961944580078
0.7937400787353516,0.32152108154296877
0.7916672124226888,0.3196209289550781
0.7903028640747071,0.32090811767578126
0.7879311528523762,0.3181239501953125
0.7863717926025391,0.31788074645996095
0.7847504404703776,0.31797120056152345
0.7836445953369141,0.3174759582519531
0.7818191411336263,0.316571533203125
0.7811461629231771,0.31567561645507813
0.7789409093221029,0.31707574768066404
0.7784856811523437,0.3171693389892578
0.7768222035725911,0.31377769470214845
0.775667839050293,0.3157054412841797
0.7744920873006185,0.31533102722167966
0.7736090128580729,0.3132479125976563
0.7724731185913086,0.3129477294921875
0.7716275736490885,0.31234914245605466
0.770503559366862,0.311773291015625
0.7696656641642252,0.31194630432128906
0.7682379526774089,0.31212035217285156
0.7675343317667643,0.31106846923828124
0.7673491032918295,0.3125599914550781
0.7658900131225586,0.3107899841308594
0.7647488942464192,0.3102849761962891
0.763827668762207,0.31017146911621096
0.7636353006998698,0.3110559448242188
0.7623023885091146,0.31141094055175783
0.7617191940307617,0.3100374237060547
0.7605737660725912,0.3110532501220703
0.7597894068400065,0.30910037231445314
0.7595597132364909,0.31143421325683596
0.758797450764974,0.30856085205078126
0.7576283635457357,0.3082192901611328
0.7574474126180013,0.30959179992675784
0.756762516784668,0.30806499938964843
0.7554874313354493,0.3091666778564453
0.7555588694254557,0.30833731994628905
