Training Loss,Test Loss
0.5661054992675781,0.6573829467773438
0.46804581807454426,0.43742616271972656
0.45055416463216147,0.4124397674560547
0.44096086985270183,0.40105426635742186
0.43443507029215495,0.39491433410644533
0.42942987670898436,0.38816703186035156
0.42486150817871093,0.38424471130371096
0.42036790211995445,0.38029512939453125
0.4165905456542969,0.37706952209472655
0.413395735168457,0.3743045715332031
0.41078978322347004,0.37211707763671875
0.40868536071777345,0.37002316589355466
0.406786979675293,0.3684266815185547
0.40528939412434895,0.36756674194335937
0.40366933085123696,0.3649535125732422
0.4022268035888672,0.3631288604736328
0.4010399139404297,0.3625369689941406
0.40003829447428385,0.3620774932861328
0.39856686401367186,0.3617594970703125
0.39773743947347007,0.35970347900390626
0.39636312459309897,0.3587641510009766
0.3955142364501953,0.3574893768310547
0.39436434275309246,0.3587552001953125
0.39376060689290365,0.3567978149414063
0.39280619659423827,0.3558326477050781
0.3920273417154948,0.3561699279785156
0.3909613484700521,0.3539803527832031
0.39047079213460284,0.35608531799316406
0.38991817372639975,0.35451253051757814
0.38926637318929036,0.35363374633789063
0.38833727264404294,0.352471826171875
0.38778578135172526,0.35304299926757815
0.3873232905069987,0.35027447204589846
0.3866773127237956,0.35024503479003904
0.3858057434082031,0.3515007843017578
0.38555045216878253,0.35121036376953124
0.3830940719604492,0.3499766296386719
0.3826880350748698,0.34770185546875
0.38269240010579425,0.3476005828857422
0.3825980941772461,0.34767589111328123
0.3824151036580404,0.3475030059814453
0.3822726262410482,0.34736785888671873
0.38224531962076824,0.3472752166748047
0.3821267588297526,0.3472262634277344
0.3819843266805013,0.34720975646972657
0.38188255259195963,0.3470959930419922
0.38180442250569663,0.347043505859375
0.38169788920084635,0.3469706268310547
0.381622314453125,0.34686730041503905
0.3815086873372396,0.34678851623535156
